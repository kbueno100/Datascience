{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Practice/Demo\n",
    "\n",
    "The following code samples are provided directly from the lesson and should serve as a jumping off point for students to run the code on their own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, metrics\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.DataFrame({'x': range(100), 'y': range(100)})\n",
    "biased_df = df.copy()\n",
    "varied_df = df.copy()\n",
    "\n",
    "def append_jitter(series,scale=1):\n",
    "    jitter = np.random.random_sample(size=len(series))\n",
    "    return [series[i] + (jitter[i] * scale) for i in xrange(len(series))]\n",
    "\n",
    "df['x'] = append_jitter(df.x)\n",
    "df['y'] = append_jitter(df.y)\n",
    "\n",
    "biased_df['y'] = biased_df['x'] **2 / (df.y.max())\n",
    "biased_df['x'] = append_jitter(biased_df.x)\n",
    "biased_df['y'] = append_jitter(biased_df.y)\n",
    "\n",
    "jitter_scale = 20\n",
    "varied_df['x'] = append_jitter(varied_df.x)\n",
    "varied_df['y'] = append_jitter(varied_df.y, scale=jitter_scale)\n",
    "\n",
    "fig,ax = plt.subplots(1,3, figsize=(18,6), sharey=True)\n",
    "sns.regplot('x','y',df, ax=ax[0])\n",
    "sns.regplot('x','y',biased_df, ax=ax[1])\n",
    "sns.regplot('x','y',varied_df, ax=ax[2])\n",
    "\n",
    "## fit\n",
    "lm = linear_model.LinearRegression().fit(df[['x']], df['y'])\n",
    "## biased fit\n",
    "lmb = linear_model.LinearRegression().fit(biased_df[['x']], biased_df['y'])\n",
    "## varied fit\n",
    "lmv = linear_model.LinearRegression().fit(varied_df[['x']], varied_df['y'])\n",
    "\n",
    "print '{} : R2 for df'.format(lm.score(df[['x']],df['y']))\n",
    "print '{} : R2 for biased_df'.format(lmb.score(biased_df[['x']],biased_df['y']))\n",
    "print '{} : R2 for varied_df'.format(lmb.score(biased_df[['x']],varied_df['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print '{} : MSE for df using lm'.format(metrics.mean_squared_error(df['y'], lm.predict(df[['x']])))\n",
    "print '{} : MSE for biased_df using lmb'.format(metrics.mean_squared_error(biased_df['y'], lmb.predict(biased_df[['x']])))\n",
    "print '{} : MSE for varied_df using lmv'.format(metrics.mean_squared_error(varied_df['y'], lmv.predict(varied_df[['x']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print '{} : MSE for biased_df using lm'.format(metrics.mean_squared_error(biased_df['y'], lm.predict(biased_df[['x']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot(df.x, df.y,kind='resid')\n",
    "sns.jointplot(biased_df.x, biased_df.y, kind='resid')\n",
    "sns.jointplot(varied_df.x, varied_df.y, kind='resid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "wd = '../../assets/dataset/'\n",
    "bikeshare = pd.read_csv(wd + 'bikeshare.csv')\n",
    "weather = pd.get_dummies(bikeshare.weathersit, prefix='weather')\n",
    "modeldata = bikeshare[['temp', 'hum']].join(weather[['weather_1', 'weather_2', 'weather_3']])\n",
    "y = bikeshare.casual\n",
    "\n",
    "kf = cross_validation.KFold(len(modeldata), n_folds=5)\n",
    "scores = []\n",
    "for train_index, test_index in kf:\n",
    "    lm = linear_model.LinearRegression().fit(modeldata.iloc[train_index], y.iloc[train_index])\n",
    "    scores.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(modeldata.iloc[test_index])))\n",
    "\n",
    "print np.mean(scores)\n",
    "\n",
    "# this score will be lower, but we're trading off bias error for generalized error\n",
    "lm = linear_model.LinearRegression().fit(modeldata, y)\n",
    "print metrics.mean_squared_error(y, lm.predict(modeldata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = cross_validation.KFold(len(modeldata), n_folds=5, shuffle=True)\n",
    "scores = []\n",
    "for train_index, test_index in kf:\n",
    "    lm = linear_model.LinearRegression().fit(modeldata.iloc[train_index], y.iloc[train_index])\n",
    "    scores.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(modeldata.iloc[test_index])))\n",
    "    \n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression().fit(modeldata, y)\n",
    "print metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "lm = linear_model.Lasso().fit(modeldata, y)\n",
    "print metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "lm = linear_model.Ridge().fit(modeldata, y)\n",
    "print metrics.mean_squared_error(y, lm.predict(modeldata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas = np.logspace(-10, 10, 21)\n",
    "for a in alphas:\n",
    "    print 'Alpha:', a\n",
    "    lm = linear_model.Ridge(alpha=a)\n",
    "    lm.fit(modeldata, y)\n",
    "    print '                {}'.format(lm.coef_)\n",
    "    print '{}\\n'.format(metrics.mean_squared_error(y, lm.predict(modeldata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search\n",
    "\n",
    "alphas = np.logspace(-10, 10, 21)\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=linear_model.Ridge(),\n",
    "    param_grid={'alpha': alphas},\n",
    "    scoring='mean_squared_error')\n",
    "\n",
    "gs.fit(modeldata, y)\n",
    "\n",
    "print 'best score: {}'.format(-gs.best_score_) # mean squared error here comes in negative, so let's make it positive.\n",
    "print 'best estimator: {}'.format(gs.best_estimator_) # explains which grid_search setup worked best\n",
    "for s in gs.grid_scores_: # shows all the grid pairings and their performances.\n",
    "    print s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_to_approach, start, steps, optimized = 6.2, 0., [-1, 1], False\n",
    "while not optimized:\n",
    "    current_distance = num_to_approach - start\n",
    "    got_better = False\n",
    "    next_steps = [start + i for i in steps]\n",
    "    for n in next_steps:\n",
    "        distance = np.abs(num_to_approach - n)\n",
    "        if distance < current_distance:\n",
    "            got_better = True\n",
    "            print distance, 'is better than', current_distance\n",
    "            current_distance = distance\n",
    "            start = n\n",
    "    if got_better:\n",
    "        print 'found better solution! using', current_distance\n",
    "        a += 1\n",
    "    else:\n",
    "        optimized = True\n",
    "        print start, 'is closest to', num_to_approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = linear_model.SGDRegressor()\n",
    "lm.fit(modeldata, y)\n",
    "print lm.score(modeldata, y)\n",
    "print metrics.mean_squared_error(y, lm.predict(modeldata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Practice\n",
    "\n",
    "Use the following code to work through the problems given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {} # put your gradient descent parameters here\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=linear_model.SGDRegressor(),\n",
    "    cv=cross_validation.KFold(len(modeldata), n_folds=5, shuffle=True),\n",
    "    param_grid=params,\n",
    "    scoring='mean_squared_error',\n",
    "    )\n",
    "\n",
    "gs.fit(modeldata, y)\n",
    "\n",
    "print 'BEST ESTIMATOR'\n",
    "print -gs.best_score_\n",
    "print gs.best_estimator_\n",
    "print 'ALL ESTIMATORS'\n",
    "print gs.grid_scores_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
